# 1000万用户电商毫秒级抽奖

背景：在双11零点从11月内关注直播间随机抽取100名幸运观众，预计全网可能有超过一千万用户参与此活动。

要求：**同一用户不能重复关注，同一名用户不允许二次中奖**。

## 方案一 基于Redis Set集合做随机弹出

在用户关注直播间写入Mysql关注用户表时，额外在Redis增加一个userlist Set集合，存储用户编号。

Redis Set可以保证全局唯一，且数据基于Hash乱序存储

```
sadd userlist xxxid
```

预计用户编号为长整型，1000W用户占空间约500MB左右，100W用户约占50MB



抽奖时，直接使用spop弹出随机100个用户编号即可，这个操作时原子性的，先弹出再返回，并且redis命令队列单线程不存在并发问题，能避免同一重复中奖的可能

```
spop userlist 100
```



之后通过执行一次select ... in语句来查找具体的用户信息，性能高并且也不会出现索引失效的问题，但要注意in集合的上限是1000个，超过1000个备选项要拆成多个in

```sql
select * from 用户表 where user_id in (xxxxx,yyyyy...)
```



## 方案二 蓄水池算法

给定一个数据流，数据长度N很大，且N直到处理完前的数据都不可知，如果想要在只遍历一次（O(N)）的情况下，能够随机选出m个不重复的数据，可以使用蓄水池算法。



当前场景可以视为数据长度N=1000W

每个样本被抽中的概率为$\frac{C^{m-1}_{m-1}}{C^m_N} = \frac{m}{N}$

所以采用的方式是前m个样本直接取出，对于大于m的样本i，以$\frac{m}{j}$的概率选择该元素，并从现有的m个样本随机选择1个位置进行替换

### 证明

对于第i个数（$i \leq m$）假设当前选择第k个数，在$k \leq m$时不被选中的概率为1

当选择第 k + 1个数时，被第k + 1个元素替换的概率 = 第k + 1 个元素被选中的概率 $\times$ i被替换的概率 = $1 \times \frac{m}{k+1} \times \frac{1}{m} = \frac{1}{k+1}$，则不被第k+1个数替换的概率为$1 \times (1 - \frac{1}{k+1}) = \frac{k}{k+1}$

当选择第 k + 2个数时，在i没有被第k + 1个数替换的前提下，被第k + 2个元素替换的概率 = 没有被第k + 1个数替换的概率 $\times$ 第k + 2 个元素被选中的概率 $\times$ i被替换的概率 = $1 \times \frac{k}{k+1} \times \frac{m}{k+2} \times \frac{1}{m} = \frac{k}{k+1} \times \frac{1}{k+2}$，不被第k+2个数替换的概率为$1 \times (\frac{k}{k+1} \times (1 - \frac{1}{k+2})) = \frac{k}{k+1} \times \frac{k+1}{k+2} = \frac{k}{k+2}$

以此类推：

当选择第N个数时，i一直没被替换的概率 = 没有被第k+1个元素被替换的概率 $\times$ 没有被第k+2个元素被替换的概率 $\times \cdots \times$ 没有被第N个元素替换的概率  = $1 \times \frac{k}{k+1} \times \frac{k}{k+2} \times \cdots \times \frac{N-1}{N} = \frac{k}{N}$

所以对于其中每个元素，被保留的概率都为$\frac{k}{N}$



java代码实现如下：

```java
public class ReservoirSamplingTest {

    private int[] pool; // 所有数据
    private final int N = 100000; // 数据规模
    private Random random = new Random();

    @Before
    public void setUp() throws Exception {
        // 初始化
        pool = new int[N];
        for (int i = 0; i < N; i++) {
            pool[i] = i;
        }
    }

    private int[] sampling(int K) {
        int[] result = new int[K];
        for (int i = 0; i < K; i++) { // 前 K 个元素直接放入数组中
            result[i] = pool[i];
        }

        for (int i = K; i < N; i++) { // K + 1 个元素开始进行概率采样
            int r = random.nextInt(i + 1);
            // 这里其实就是k/j的体现
            if (r < K) {
                result[r] = pool[i];
            }
        }

        return result;
    }

    @Test
    public void test() throws Exception {
        for (int i : sampling(100)) {
            System.out.println(i);
        }
    }
}
```



# SOFA Registry的各种优化点

链接如下：https://segmentfault.com/a/1190000042736139



# MOSN 与 SOFA Registry构建特定标签实例子集优化

链接全文如下https://www.sofastack.tech/blog/build-subset-optimization/

原来的每个metadata中存储了MOSN的特定标签，如zone、version，根据此建立各标签组合（[zone]、[version]、[zone、version]，标签越多子集越多）的实例组合时，每个标签的子集就需要遍历一次实例列表和一次去重，标签越多性能越差

解决的方式为**构建标签的倒排索引**：需要的话可以先为实例列表进行一次去重，然后为[zone]、[version]等标签的所有值建立一个存储0/1的bitmap作为倒排索引，遍历一次实例列表，并修改对应标签位图的对应位，示例如下

```json
{
    "zone":{
        "zone1":bitmap(110),
        "zone2":bitmap(001)
    },
    "version":{
        "v1":bitmap(100),
        "v2":bitmap(010),
        "v3":bitmap(001)
    }
}
```

对于标签的组合的子集，可以使用bitmap进行交集快速得到子标签对应的实例列表。
