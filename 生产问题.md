# 生产问题排查常用命令

如果有线程阻塞的情况，可以使用jstack多抓几次查看线程的栈

```shell
jstack pid > xxx.log
```



如果要查看gc情况，可以使用

```shell
jstat -gcutil pid 时间间隔（毫秒）
```



如果出现了内存溢出，可以抓堆栈，其中live参数是抓当前存活的对象，会触发一次Full GC，要根据实际情况添加

```shell
jmap -dump:live,format=b,file=output.hprof pid
```

也可以在jvm参数中加入参数

```
-XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=./logs/oomDump.hprof
```



如果要进行网络抓包，则可以使用

```shell
tcpdump - ni eth0 port xxxx -w yyy.cap
```





# 实际问题：

## 1、邮件服务健康检查失败导致重启

引用了springboot的actuator健康检查组件后，检查到引用了mail、redis、es等starter后，会定期请求这些服务检查服务是否正常。邮件服务短时间不可用导致mail健康检查失败，导致健康检查整体失败最后重启。





## 2、服务治理的网关开启Spring Cloud Gateway自带的限流后，会出现交易阻塞的情况

这个网关利用redis的发布订阅，来及时更新路由，同时也使用了gateway自带的限流功能。其中有一段特殊的代码，目的是在redis集群发生变化时，重新在新的节点上订阅对应的key，此问题其实是多个极端问题结合才能触发：启用gateway的redis限流，使用gateway的lb负载，限流路由数>=cpu数量

这段代码可以发现是摘抄自网络https://www.cnblogs.com/xfearless/p/11393438.html，核心问题代码如下，其中网关把这里的jedis直接换成了lettuce：

```java
public class RedisMessageListenerFactory implements BeanFactoryAware, ApplicationListener<ContextRefreshedEvent> {

    @Value("${spring.redis.password}")
    private String password;
    
    private DefaultListableBeanFactory beanFactory;

    private RedisConnectionFactory redisConnectionFactory;

    @Autowired
    private MessageListener messageListener;

    public void setBeanFactory(BeanFactory beanFactory) throws BeansException {
        this.beanFactory = (DefaultListableBeanFactory) beanFactory;
    }

    public void setRedisConnectionFactory(RedisConnectionFactory redisConnectionFactory) {
        this.redisConnectionFactory = redisConnectionFactory;
    }

    @Override
    public void onApplicationEvent(ContextRefreshedEvent contextRefreshedEvent) {
        RedisClusterConnection redisClusterConnection = redisConnectionFactory.getClusterConnection();
        if (redisClusterConnection != null) {
            Iterable<RedisClusterNode> nodes = redisClusterConnection.clusterGetNodes();
            for (RedisClusterNode node : nodes) {
                if (node.isMaster()) {
                    String containerBeanName = "messageContainer" + node.hashCode();
                    if (beanFactory.containsBean(containerBeanName)) {
                        return;
                    }
                    JedisShardInfo jedisShardInfo = new JedisShardInfo(node.getHost(), node.getPort());
                    jedisShardInfo.setPassword(password);
                    JedisConnectionFactory factory = new JedisConnectionFactory(jedisShardInfo);
                    BeanDefinitionBuilder containerBeanDefinitionBuilder = BeanDefinitionBuilder
                            .genericBeanDefinition(RedisMessageListenerContainer.class);
                    containerBeanDefinitionBuilder.addPropertyValue("connectionFactory", factory);
                    containerBeanDefinitionBuilder.setScope(BeanDefinition.SCOPE_SINGLETON);
                    containerBeanDefinitionBuilder.setLazyInit(false);
                    beanFactory.registerBeanDefinition(containerBeanName,
                            containerBeanDefinitionBuilder.getRawBeanDefinition());

                    RedisMessageListenerContainer container = beanFactory.getBean(containerBeanName,
                            RedisMessageListenerContainer.class);
                    String listenerBeanName = "messageListener" + node.hashCode();
                    if (beanFactory.containsBean(listenerBeanName)) {
                        return;
                    }
                    container.addMessageListener(messageListener, new PatternTopic("__keyevent@0__:expired"));
                    container.start();
                }
            }
        }
    }

}
```

问题主要部分在`ApplicationListener<ContextRefreshedEvent>`、和一开始的获取sentinel连接上`RedisClusterConnection redisClusterConnection = redisConnectionFactory.getClusterConnection();`。

ContextRefreshedEvent事件在spring的生命周期中是会多次触发的，在spring cloud gateway中，使用lb方式进行负载均衡时，初次触发某个路由会通过synchronized加锁对路由进行初始化并调用Refresh方法刷新容器，最终导致ContextRefreshedEvent事件多次触发。而这个事件内部的建立连接操作用的是lettuce官方不推荐的同步阻塞方式，存在了线程永久阻塞的风险，若不开启Gateway的限流并不会触发此问题。此外Gateway底层使用的reactor netty，lettuce底层也是netty，大概率是netty存在bug，导致请求从reactor的线程在限流查询时切换为lettuce线程后，不会正常切换回来，最终导致lettuce线程去执行获取sentinel连接的操作，而这个操作底层是netty的EventLoopGroup通过轮询对应的lettuce线程去获取，导致同一个线程阻塞等待连接，同时需要该线程去获取，最终该线程无限阻塞，同时gateway创建路由的锁也将无限阻塞，导致最终Gateway接不了新交易。

线程数和cpu相等才会卡的原因：redis限流会用固定的一个lettuce建立连接并以后直接获取，EventLoopGroup轮询机制导致最终该线程轮询cpu次到达自己与自己的卡死情况。





## 3、日志框架由log4j替换为logback

springboot的默认日志框架就是logback

commons-logging + log4j的组合可以被slf4j + logback替换，其中comms-logging和slf4j是接口，而log4j和logback分别是他们的实现

log4j不改代码直接替换为logback的方式：

排除log4j和commons-logging的相关依赖

然后引入如下依赖（版本号根据实际情况修改）：

```xml
<!-- 引入slf4j -->
<dependency>
	<groupId>org.slf4j</groupId>
	<artifactId>slf4j-api</artifactId>
	<version>1.7.32</version>
</dependency>
<!-- 引入logback -->
<dependency>
	<groupId>ch.qos.logback</groupId>
	<artifactId>logback-core</artifactId>
	<version>1.2.9</version>
</dependency>
<dependency>
	<groupId>ch.qos.logback</groupId>
	<artifactId>logback-classic</artifactId>
	<version>1.2.9</version>
</dependency>
<!-- commons-logging的桥接工具，解决删除commons-logging后的类缺失问题 -->
<dependency>
	<groupId>org.slf4j</groupId>
	<artifactId>jcl-over-slf4j</artifactId>
	<version>1.7.32</version>
</dependency>
<!-- log4j的桥接工具，解决删除log4j后的类缺失问题（一般代码中没用接口而是直接使用的实现类才需要这个）-->
<dependency>
	<groupId>org.slf4j</groupId>
	<artifactId>log4j-over-slf4j</artifactId>
	<version>1.7.32</version>
</dependency>
```

